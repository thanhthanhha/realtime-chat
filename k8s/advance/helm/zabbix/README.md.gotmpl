# Helm chart for Zabbix

[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0) {{ template "chart.versionBadge" . }} [![Downloads](https://img.shields.io/github/downloads/zabbix-community/helm-zabbix/total?label=Downloads%20All%20Releases
)](https://tooomm.github.io/github-release-stats/?username=zabbix-community&repository=helm-zabbix)


{{ template "chart.description" . }}

This Helm chart installs [Zabbix](https://www.zabbix.com) in a Kubernetes cluster. It supports only Postgresql/TimescaleDB as a database backend at this point in time, without any plans to extend database support towards MySQL, MariaDB, etc. Also, this Helm Chart supports [Zabbix Server High Availability](#native-zabbix-server-high-availability)

# Table of Contents
<!-- TOC -->

- [Helm chart for Zabbix](#helm-chart-for-zabbix)
- [Table of Contents](#table-of-contents)
- [Prerequisites](#prerequisites)
- [Installation](#installation)
- [How to access Zabbix](#how-to-access-zabbix)
- [Troubleshooting](#troubleshooting)
- [Uninstallation](#uninstallation)
- [Breaking changes of this helm chart](#breaking-changes-of-this-helm-chart)
  - [Version 7.0.0](#version-700)
  - [Version 6.1.0](#version-610)
  - [Version 6.0.0](#version-600)
  - [Version 5.0.0](#version-500)
  - [Version 4.0.0](#version-400)
  - [Version 3.0.0](#version-300)
  - [Version 2.0.0](#version-200)
  - [Version 1.0.0](#version-100)
- [Zabbix components](#zabbix-components)
  - [Zabbix Server](#zabbix-server)
  - [Zabbix Agent](#zabbix-agent)
  - [Zabbix Web (frontend)](#zabbix-web-frontend)
  - [Zabbix Web Service](#zabbix-web-service)
  - [Zabbix Proxy](#zabbix-proxy)
  - [PostgreSQL](#postgresql)
- [Thanks](#thanks)
- [License](#license)
- [Configuration](#configuration)
  - [Helm Values](#helm-values)
  - [Database access settings](#database-access-settings)
  - [Postgresql database](#postgresql-database)
  - [Native Zabbix Server High Availability](#native-zabbix-server-high-availability)
  - [Expose Zabbix service](#expose-zabbix-service)
  - [Multiple replicas for Zabbix Proxy statefulset](#multiple-replicas-for-zabbix-proxy-statefulset)

<!-- TOC -->

# Prerequisites

- Kubernetes cluster 1.21+
- Helm 3.0+
- Kubectl
- PV provisioner support in the underlying infrastructure (optional).

Install the ``kubectl`` and ``helm`` requirements following the instructions in this [tutorial](docs/requirements.md).

# Installation

> [!IMPORTANT]
> Read the [Breaking changes of this helm chart](#breaking-changes-of-this-helm-chart)!

Access the Kubernetes cluster.

Add Helm repository:

```bash
helm repo add zabbix-community https://zabbix-community.github.io/helm-zabbix
```

Update the list helm charts available for installation. This is recommend prior to installation/upgrade:

```bash
helm repo update
```

Get all versions of helm chart:

```bash
helm search repo zabbix-community/zabbix -l
```

Set the helm chart version you want to use. Example:

```bash
export ZABBIX_CHART_VERSION='{{ template "chart.version" . }}'
```

Export default values of ``zabbix`` chart to ``$HOME/zabbix_values.yaml`` file:

```bash
helm show values zabbix-community/zabbix --version $ZABBIX_CHART_VERSION > $HOME/zabbix_values.yaml
```

Change the values according to the environment in the ``$HOME/zabbix_values.yaml`` file. The items of [Configuration](#configuration) section can be set via ``--set`` flag in 
installation command or change the values according to the need of the environment in ``$HOME/zabbix_values.yaml`` file.

Test the installation/upgrade with the command:

```bash
helm upgrade --install zabbix zabbix-community/zabbix \
 --dependency-update \
 --create-namespace \
 --version $ZABBIX_CHART_VERSION \
 -f $HOME/zabbix_values.yaml -n monitoring --debug --dry-run
```

Install/upgrade Zabbix with the command:

```bash
helm upgrade --install zabbix zabbix-community/zabbix \
 --dependency-update \
 --create-namespace \
 --version $ZABBIX_CHART_VERSION \
 -f $HOME/zabbix_values.yaml -n monitoring --debug
```

See the installation example in [kind](https://kind.sigs.k8s.io) cluster in this [tutorial](docs/example/README.md).

# How to access Zabbix

Create port-forward for Zabbix:

```bash
kubectl port-forward service/zabbix-zabbix-web 8888:80 -n monitoring
```

Login to Zabbix:

- URL: http://localhost:8888
- Login: **Admin**
- Password: **zabbix**

# Troubleshooting

See the pods:

```bash
kubectl get pods -n monitoring
```

See details for each pod:

```bash
kubectl describe pods/POD_NAME -n monitoring
```

See all containers in the pod:

```bash
kubectl get pods POD_NAME -n monitoring -o jsonpath='{.spec.containers[*].name}*'
```

See the logs for each container in the pod:

```bash
kubectl logs -f pods/POD_NAME -c CONTAINER_NAME -n monitoring
```

Access the container prompt.

```bash
kubectl exec -it pods/POD_NAME -c CONTAINER_NAME -n monitoring -- sh
```

See details of Zabbix services.

```bash
kubectl get svc -n monitoring
kubectl get pods --output=wide -n monitoring
kubectl describe services zabbix -n monitoring
```

# Uninstallation

To uninstall/delete the ``zabbix`` deployment:

```bash
helm uninstall zabbix -n monitoring
```

# Breaking changes of this helm chart

## Version 7.0.0

> [!CAUTION]
> Re-installation of your Release will be necessary. Make sure you do not lose any data!

- Changed values under `postgresAccess`, partially made necessary by changing *db-create-upgrade-job* for [Native Zabbix Server High Availability](#native-zabbix-server-high-availability) to be a *pre-install/pre-upgrade* job:
  - removed `postgresAccess.useUnifiedSecret`. It's now ALWAYS a unified secret containing DB connection relevant settings that is used by all components of this Chart requiring a DB connection
  - `unifiedSecretName` now called `existingSecretName` to be more compliant with other Helm Charts
  - `unifiedSecretAutoCreate` has been removed. Secret generation now depends on having set `existingSecretName`
  - `unifiedSecretXXXKey` renamed to simpler `secretXXXKey` value names
- Default settings in `values.yaml` are now `postgresql.enabled=true` (no change here) and `zabbixServer.zabbixServerHA=false` (changed, due to [Native Zabbix Server High Availability](#native-zabbix-server-high-availability))
- All labels of all manifests have been unified to fulfill the best practices / standards of how a newly created helm chart (`helm create...`) would do it. This results in you having to **uninstall and install your Release again**, as `spec.selector` label matchers are *immutable* for *Deployments*, *Statefulsets* and such. If you use `postgresql.enabled=true` ("internal database"), be careful not to delete your Zabbix database when issuing uninstallation. By default, Helm does not remove *PersistentVolumeClaims* when uninstalling a release, but to be sure, you can [annotate your PVC additionally](https://github.com/helm/helm/issues/6261#issuecomment-523472128) to prevent its deletion
- Removed all pre 1.21 Kubernetes compatibility switches (`v1beta1`, ...)
- `deploymentAnnotations` have been renamed to `extraDeploymentAnnotations` for every of the components of this helm chart in `values.yaml`
- `deploymentLabels` have been renamed to `extraDeploymentLabels` for every of the components of this helm chart in `values.yaml`. The same counts for `statefulSetLabels`, etc.
- `deploymentAnnotations` have been renamed to `extraDeploymentAnnotations` for every of the components of this helm chart in `values.yaml`. The same counts for `statefulSetAnnotations`, `daemonSetAnnotations`, etc.
- `containerLabels` are now called `extraPodLabels` and `containerAnnotations` went to be `extraPodAnnotations`, as these names match better to what the values actually do
- when using `zabbixAgent.runAsDaemonSet=true`, zabbix agent pods now default to use `hostNetwork: true`

## Version 6.1.0

- Removing support for non-default Kubernetes features and Custom Resource objects: `IngressRoute`, `Route`, more info: [#123](https://github.com/zabbix-community/helm-zabbix/pull/123)
- Removing support for [karpenter](https://karpenter.sh) due to the more generalistic approach: [#121](https://github.com/zabbix-community/helm-zabbix/pull/121)
- Adding support to deploy any arbitrary manifests together with this Helm Chart by embedding them in the `.Values.extraManifests` list [#121](https://github.com/zabbix-community/helm-zabbix/pull/121)
- From now on, the keys to use for a `unifiedSecret` to configure postgresql access globally for all relevant components that this Helm Chart deploys, can be configured in `values.yaml` file
- It is now possible to use a different Schema other than `public` in Postgresql database, when using an external database

## Version 6.0.0

- New implementation of native Zabbix Server High Availability (see [Support of native Zabbix Server High Availability](#support-of-native-zabbix-server-high-availability) section)
- No breaking changes in values.yaml, but nevertheless you might want to review your values.yaml's `zabbixServer.zabbixServerHA` section

## Version 5.0.0

- Will be using Postgresql 16.x and Zabbix 7.x.
- Adjust in extraEnv to add support in environment variables from configmap and secret. More info: #93

## Version 4.0.0

- Will be used Postgresql 15.x and Zabbix 6.x.
- Allow install zabbix-agent2 as deployment and sidecar container. More info: https://github.com/zabbix-community/helm-zabbix/issues/20
- This release changes parameter names in preparation for addressing these issues in the future and use [camelCase](https://en.wikipedia.org/wiki/Camel_case) pattern where is possible. More info: https://github.com/zabbix-community/helm-zabbix/issues/18 and https://github.com/zabbix-community/helm-zabbix/issues/21
  - ``db_access`` -> ``postgresAccess``
  - ``db_access.use_unified_secret`` -> ``postgresAccess.useUnifiedSecret``
  - ``db_access.unified_secret_name`` -> ``postgresAccess.unifiedSecretName``
  - ``db_access.unified_secret_autocreate`` -> ``postgresAccess.unifiedSecretAutoCreate``
  - ``db_access.db_server_host`` -> ``postgresAccess.host``
  - ``db_access.db_server_port`` -> ``postgresAccess.port``
  - ``db_access.postgres_user`` -> ``postgresAccess.user``
  - ``db_access.postgres_password`` -> ``postgresAccess.password``
  - ``db_access.postgres_db`` -> ``postgresAccess.database``
  - ``db_access.postgres_password_secret`` -> ``postgresAccess.passwordSecret``
  - ``db_access.postgres_password_secret_key`` -> ``postgresAccess.passwordSecretKey``
  - ``ingressroute`` -> ``ingressRoute``
  - ``postgresql.existing_claim_name`` -> ``postgresql.existingClaimName``
  - ``postgresql.storage_size`` -> ``postgresql.storageSize``
  - ``postgresql.storage_class`` -> ``postgresql.storageClass``
  - ``zabbix_image_tag`` -> ``zabbixImageTag``
  - ``zabbixagent`` -> ``zabbixAgent``
  - ``zabbixproxy`` -> ``zabbixProxy``
  - ``zabbixserver`` -> ``zabbixServer``
  - ``zabbixserver.pod_anti_affinity`` -> ``zabbixServer.podAntiAffinity``
  - ``zabbixserver.ha_nodes_autoclean`` -> ``zabbixServer.haNodesAutoClean``
  - ``zabbixserver.ha_nodes_autoclean.delete_older_than_seconds`` -> ``zabbixServer.haNodesAutoClean.deleteOlderThanSeconds``
  - ``zabbixweb`` -> ``zabbixWeb``
  - ``zabbixweb.pod_anti_affinity`` -> ``zabbixWeb.podAntiAffinity``
  - ``zabbixweb.saml_certs_secret_name`` -> ``zabbixWeb.samlCertsSecretName``
  - ``zabbixwebservice`` -> ``zabbixWebService``
  - ``zabbixwebservice.pod_anti_affinity`` -> ``zabbixWebService.podAntiAffinity``
  - ``zabbixwebservice.ignore_url_cert_errors`` -> ``zabbixWebService.ignoreURLCertErrors``

## Version 3.0.0

- Will be used Postgresql 14.x and Zabbix 6.x.
- This version removes the possibility to specify database username/password per
  subsection in favor of specifying all of them centrally at one place.
- Also, the names of the values have changed from upper to lowercase.
- It is now possible to start the Zabbix Server pods with replicas of more than 1.
  HA functionality of Zabbix will automatically be enabled and it is made sure that 
  the database schema publication will only happen once, and not by all of the Zabbix
  Server pods at the same time.
- More info: https://github.com/cetic/helm-zabbix/pull/54

## Version 2.0.0

- Will be used Postgresql 14.x and Zabbix 6.x.
- This version implements a central way of managing database access credentials 
using a secret, which then will be respected by all the components
installed by this chart: zabbixServer, zabbixWeb and postgresql.
- The secret must contain a number of keys indicating DB host, DB name,
user and password and can direct towards a database installed within
this chart, or an external database.
- The benefit of this is that now the database can respect the values 
in the central DB access secret and initialize accordingly.
- Last but not least, the credential secret can be chosen to be
auto-generated (password will be set to a random string) at chart
installation, if postgresql.enabled is set to true. With this, an easy
to use "out-of-the-box" installation with as little customizations as
possible is possible, while still obtaining a good level of security.
- More info: https://github.com/cetic/helm-zabbix/pull/53

## Version 1.0.0

- Will be used Postgresql 14.x and Zabbix 6.x.
- The installation of any component of chart is optional for easy integration with the official
 chart: https://git.zabbix.com/projects/ZT/repos/kubernetes-helm/
- More info: https://github.com/cetic/helm-zabbix/issues/42

# Zabbix components

> [!NOTE]
> About the Zabbix version supported

- This helm chart is compatible with non-LTS version of Zabbix, that include important changes and functionalities. 
- But by default this helm chart will install the latest LTS version (example: 7.0.x). 
See more info in [Zabbix Life Cycle & Release Policy](https://www.zabbix.com/life_cycle_and_release_policy) page
- When you want use a non-LTS version (example: 7.2.x), you have to set this in ``values.yaml`` yourself. This Helm Chart is actively being tested with the current non-LTS major releases, so it will be most probably working without any problem just setting `zabbixImageTag`, for example to the value of `ubuntu-7.2.1` or `alpine-7.2-latest`.

## Zabbix Server

**Zabbix Server** is the central process of Zabbix software.

The server performs the polling and trapping of data, it calculates triggers, sends notifications 
to users. It is the central component to which Zabbix agents and proxies report data on availability 
and integrity of systems. The server can itself remotely check networked services (such as web servers 
and mail servers) using simple service checks 
[Official documentation](https://www.zabbix.com/documentation/current/en/manual/concepts/server).

Zabbix Server can be operated in a High Availability mode since version 6.0 which is automatically 
enabled by this Helm chart when setting the Zabbix Server component to run more than 1 replica. 
In this HA mode, all Zabbix Server instances periodically send a heartbeat to the Database server 
(just updating a timestamp in a table) as well as which of the nodes is the "active" one. In case 
the active node does not send a heartbeat within a certain time, any of the remaining ones 
automatically take over. It is every time possible to join new nodes to the HA cluster by just
raising the amount of replicas of the Zabbix Server.


## Zabbix Agent

> [!NOTE]
> **zabbix-agent2** is supported in this helm chart and will be used by default.

**Zabbix Agent** is deployed on a monitoring target to actively monitor local resources and 
applications (hard drives, memory, processor statistics etc)
[Official documentation](https://www.zabbix.com/documentation/current/en/manual/concepts/agent).


## Zabbix Web (frontend)

**Zabbix Web** interface is a part of Zabbix software. It is used to manage resources under 
monitoring and view monitoring statistics 
[Official documentation](https://www.zabbix.com/documentation/current/en/manual/web_interface).

## Zabbix Web Service

**Zabbix Web Service** is a process that is used for communication with external web services 
[Official documentation](https://www.zabbix.com/documentation/current/en/manual/concepts/web_service).

## Zabbix Proxy

> [!NOTE]
> This helm chart installs Zabbix Proxy with SQLite3 support

**Zabbix Proxy** is a process that may collect monitoring data from one or more monitored devices 
and send the information to the Zabbix Server, essentially working on behalf of the server. 
All collected data is buffered locally and then transferred to the **Zabbix Server** the 
proxy belongs to 
[Official documentation](https://www.zabbix.com/documentation/current/en/manual/concepts/proxy).

## PostgreSQL

A database is required for zabbix to work, in this helm chart we're using Postgresql.

> [!IMPORTANT]
> We use plain postgresql database by default WITHOUT persistence. If you want persistence or 
would like to use TimescaleDB instead, check the comments in the ``values.yaml`` file.

# Thanks

> **About the new home of helm chart**
- The new home of the Zabbix helm chart is: https://github.com/zabbix-community/helm-zabbix.
It is a fork from the [cetic/helm-zabbix](https://github.com/cetic/helm-zabbix).
- In this [issue](https://github.com/cetic/helm-zabbix/issues/68) it was agreed with [Sebastien Dupont](https://github.com/banzothat) that the repository would get a new home.
- We are grateful to [Cetic](https://www.cetic.be/) for making the infrastructure available on CircleCI to host the helm chart from the start. Now, the new versions will be hosted on Github.
- We are very grateful to [Alexandre Nuttinck](https://github.com/alexnuttinck) and [Amen Ayadi](https://github.com/AyadiAmen), who were the first developers of the helm chart and who worked at Cetic. Your dedication and effort made it possible to install Zabbix on a Kubernetes cluster.

# License

[Apache License 2.0](/LICENSE)

# Configuration

## Helm Values

The following tables lists the configurable parameters of the chart and their default values.

{{ template "chart.valuesTable" . }}

## Database access settings

All settings referring to how the different components that this Chart installs access the 
Zabbix PostgreSQL Database (either an external, already existing database or one deployed within 
this Helm chart) are being configured centrally under the ``postgresAccess`` section of the 
``values.yaml`` file.

By default, this Chart will deploy it's own very simple PostgreSQL database. All settings 
relevant to how to access this database will be held in one central *Secret* with the 
name of the *Helm Release*, suffixed with *-db-access* and values defined in ``values.yaml``.

Instead of letting the Chart automatically generate such a secret, you can use an existing Secret. 
Use ``postgresAccess.externalSecretName`` in such a case and read the comments 
in ``values.yaml`` for how the keys inside the Secret holding the relevant values can be set.

If you want to connect your Zabbix installation to a Postgres database deployed using the 
[CrunchyData PGO Operator](https://access.crunchydata.com/documentation/postgres-operator/latest/), 
you can use the secret that PGO/CNPG generates for your database directly to connect Zabbix to it, 
by just referring to its name with the ``postgresAccess.externalSecretName`` setting to it.

## Postgresql database

While the default database configuration shipped with this Chart is fine for most (very small, 
for testing only) Zabbix installations, you will want to set some specific settings to better 
match your setup. First of all, you should consider enabling Postgresql database persistence 
(``postgresql.persistence.enabled``), as otherwise all your changes and historical data will 
be gone as soon as you remove the installation of Zabbix. Additionally, you might want to tune 
Postgresql by supplying extra postgresql runtime parameters using the 
``postgresql.extraRuntimeParameters`` dictionary:

```yaml
postgresql:
  enabled: true
  persistence:
    enabled: true
    storageSize: 50Gi
  extraRuntimeParameters:
    max_connections: 250
    dynamic_shared_memory_type: posix
    shared_buffers: 4GB
    temp_buffers: 16MB
    work_mem: 128MB
    maintenance_work_mem: 256MB
    effective_cache_size: 6GB
    min_wal_size: 80MB
```

Alternatively, you can add your own configuration file for postgresql (using a ConfigMap and 
the ``postgresql.extraVolumes`` setting) to mount it into the postgresql container and referring 
to this config file with the ``postgresql.extraRuntimeParameters`` set to:

```yaml
postgresql:
  extraRuntimeParameters:
    config.file: /path/to/your/config.file
```

Much more than using the database deployment done by this Helm Chart, it is highly recommended, and for usage of the [Zabbix Server High Availability](#native-zabbix-server-high-availability) even necessary, is the usage of an external database employing proper Backup, Restore, and High Availability functionalities. A good, and probably the best, way to do this inside Kubernetes is using one of the Postgresql database operators [CrunchyData PGO Operator](https://access.crunchydata.com/documentation/postgres-operator/latest/) or [CNPG](https://cloudnative-pg.io) See [Examples](/docs/examples/). For CNPG, a simple database manifest could look as follows:

```yaml
apiVersion: postgresql.cnpg.io/v1
kind: Cluster
metadata:
  name: zabbix-db
spec:
  instances: 3
  imageName: ghcr.io/cloudnative-pg/postgresql:16
  storage:
    size: 5Gi
```

## Native Zabbix Server High Availability

Since version 6.0, Zabbix has its own implementation of [High Availability](https://www.zabbix.com/documentation/current/en/manual/concepts/server/ha), which is a simple approach to realize a Hot-Standby high availability setup with Zabbix Server. This feature applies only to the Zabbix Server component, not Zabbix Proxy, Webdriver, Web Frontend or such. In a Zabbix monitoring environment, by design, there can only be one central active Zabbix Server taking over the responsibility of storing data into database, calculating triggers, sending alerts, evt. The native High Availability concept does not change that, it just implements a way to have additional Zabbix Server processes being "standby" and "jumping in" as soon as the active one does not report it's availability (updating a table in the database), anymore. As such, the Zabbix Server High Availability works well together (and somewhat requires, to be an entirely high available setup), an also high available database setup. High availability of Postgres Database is not covered by this Helm Chart, but can rather easily be achieved by using one of the well-known Postgresql database operators [PGO](https://github.com/CrunchyData/postgres-operator) and [CNPG](https://cloudnative-pg.io), which are supported to be used with this Helm Chart.

> [!IMPORTANT]
> In order to deploy Zabbix Server in High Available mode using this Helm Chart, you need to bring your own (external) database. Recommended is to supply a highly available Postgresql setup using one of the well-known Postgresql operators [PGO](https://github.com/CrunchyData/postgres-operator) or [CNPG](https://cloudnative-pg.io) See [Examples](/docs/examples/).

For the HA feature, which has not been designed for usage in Kubernetes by Zabbix SIA, to work in K8S, there have been some challenges to overcome, primarily the fact that Zabbix Server does not allow to upgrade or to initialize database schema when running in HA mode enabled. Intention by Zabbix is to turn HA mode off, issue Major Release Upgrade, turn HA mode back on. This doesn't conclude with Kubernetes concepts. Beside of that, some additional circumstances led us to an implementation as follows:

- added a portion in values.yaml generally switching *Zabbix Server HA* on or off. If turned off, the Zabbix Server deployment will always be started with 1 replica and without the ZBX_HANODENAME env variable. This is an easy-to-use setup with no additional job pods, but it's not possible to just scale up zabbix server pods from here
- when `.Values.zabbixServer.zabbixServerHA.enabled` is set to `true`, a Kubernetes Job, marked as Helm *pre-install,pre-upgrade* hook, is being deployed used to prepare the database and the database's schema version (by "schema", we refer to the tables, their structure, etc.) prior to any Zabbix Server pods trying to access the database. This job also handles major release upgrades. In case the job is being started in a `helm upgrade` situation, it scales down zabbix server deployment before upgrading database schema, manages entries in the DBs `ha_node` table, etc. Additionally, this job figures out whether a migration from a non-HA enabled setup to a HA-enabled one has been done, and handles necessary actions (scale down pods, delete entries in database) accordingly. The image bases off the zabbix_server image and its source code can be found [here](https://github.com/zabbix-community/helm-zabbix-image-db-init-upgrade-job).

Due to the way Helm works (not offering a possibility to deploy manifests BEFORE a pre-install/pre-upgrade job) and the need to implement the database preparation as such (Helm never finishing an installation when using `--wait` flag when using post-install/post-upgrade job instead, and ArgoCD suffering the same issue), it is **not supported** to have this Helm Chart deploying the database Pod itself (`postgresql.enabled`) and enabling the Zabbix Server HA mode. `postgresql.enabled` is meant for non-production / test use cases, when for production an external database or one managed by an operator, set up in a high available manner, is strongly recommended anyway.

In order to make it possible to use **Active checks** and **Active Zabbix Proxies** with a Zabbix Server setup having High Availability enabled, a **HA Labels sidecar** has been introduced, continuously monitoring the Zabbix server pod for amount of running Zabbix server processes to figure out whether the Pod is being "active" or "standby" Zabbix Server node, and updating HA-related labels on the pod, accordingly. The image for these sidecar containers is been contained [here within this Github organization](https://github.com/zabbix-community/helm-zabbix-image-ha-labels-sidecar). The reason to implement it this way and not by probing the port number, which was my initial approach, is that probing the port of Zabbix Server will make it generate a message in the log, stating that a connection without a proper payload has been initiated towards the Zabbix Server. More info: #115

## Expose Zabbix service

- **Ingress**: The ingress controller must be installed in the Kubernetes cluster.
- **ClusterIP**: Exposes the service on a cluster-internal IP. Choosing this value makes the 
service only reachable from within the cluster.
- **NodePort**: Exposes the service on each Node's IP at a static port (the NodePort). 
You'll be able to contact the NodePort service, from outside the cluster, by requesting 
``NodeIP:NodePort``.
- **LoadBalancer**: Exposes the service externally using a cloud provider's load balancer.

## Multiple replicas for Zabbix Proxy statefulset

In case you use proxy groups, it may be necessary to have several zabbix proxy replicas.
you can then no longer set the ZBX_HOSTNAME value.
This value will then take the name of each pod.
Name that you can then give to your zabbix proxies on the zabbix server side.

> [!IMPORTANT]
> You will need to deploy proxy service per replica if you want the Active Agent checks to work.
> **If not defined the pod name will be used.**
